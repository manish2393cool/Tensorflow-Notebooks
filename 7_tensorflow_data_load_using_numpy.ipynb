{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow data load using numpy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish2393cool/Tensorflow-Notebooks/blob/master/7_tensorflow_data_load_using_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TfRdquslKbO3"
      },
      "source": [
        "# Load NumPy Data with tf.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-0tqX8qkXZEj"
      },
      "source": [
        "This tutorial provides an example of loading data from NumPy arrays into a `tf.data.Dataset`.\n",
        "\n",
        "This example loads the MNIST dataset from a `.npz` file. However, the source of the NumPy arrays is not important.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Ze5IBx9clLB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D1gtCQrnNk6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "899c1788-524a-4972-ca5e-917661389647"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k6J3JzK5NxQ6",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        " \n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G0yWiN8-cpDb"
      },
      "source": [
        "### Load from `.npz` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GLHNrFM6RWoM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "18accb58-c9fb-4fd2-b8dc-22e4ffc86509"
      },
      "source": [
        "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
        "\n",
        "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
        "with np.load(path) as data:\n",
        "  train_examples = data['x_train']\n",
        "  train_labels = data['y_train']\n",
        "  test_examples = data['x_test']\n",
        "  test_labels = data['y_test']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cCeCkvrDgCMM"
      },
      "source": [
        "## Load NumPy arrays with `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tslB0tJPgB-2"
      },
      "source": [
        "Assuming you have an array of examples and a corresponding array of labels, pass the two arrays as a tuple into `tf.data.Dataset.from_tensor_slices` to create a `tf.data.Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QN_8wwc5R7Qm",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Rco85bbkDfN"
      },
      "source": [
        "## Use the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0dvl1uUukc4K"
      },
      "source": [
        "### Shuffle and batch the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GTXdRMPcSXZj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w69Jl8k6lilg"
      },
      "source": [
        "### Build and train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uhxr8py4DkDN",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XLDzlPGgOHBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "426bc261-2f61-441c-8110-3888a12ff1b7"
      },
      "source": [
        "model.fit(train_dataset, epochs=10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c978176a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f3c978176a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 3.3406 - sparse_categorical_accuracy: 0.8779\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5018 - sparse_categorical_accuracy: 0.9269\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.3860 - sparse_categorical_accuracy: 0.9436\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3224 - sparse_categorical_accuracy: 0.9523\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.3013 - sparse_categorical_accuracy: 0.9582\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2704 - sparse_categorical_accuracy: 0.9640\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2614 - sparse_categorical_accuracy: 0.9667\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2388 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2300 - sparse_categorical_accuracy: 0.9713\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2118 - sparse_categorical_accuracy: 0.9733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c9779e518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2q82yN8mmKIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b13ded2c-567d-4f44-b246-cec3741a1172"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 3ms/step - loss: 0.5682 - sparse_categorical_accuracy: 0.9625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5682040575452046, 0.9625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}