{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow data load using pandas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish2393cool/Tensorflow-Notebooks/blob/master/6_tensorflow_data_load_using_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YQB7yiF6v9GR"
      },
      "source": [
        "# Load pandas dataframes with tf.data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UmyEaf4Awl2v"
      },
      "source": [
        "This tutorial provides an example of how to load pandas dataframes into a `tf.data.Dataset`.\n",
        "\n",
        "This tutorials uses a small [dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) provided by the Cleveland Clinic Foundation for Heart Disease. There are several hundred rows in the CSV. Each row describes a patient, and each column describes an attribute. We will use this information to predict whether a patient has heart disease, which in this dataset is a binary classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iiyC7HkqxlUD"
      },
      "source": [
        "## Read data using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5IoRbCA2n0_V",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-2kBGy_pxn47"
      },
      "source": [
        "Download the csv file containing the heart dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VS4w2LePn9g3",
        "colab": {}
      },
      "source": [
        "csv_file = tf.keras.utils.get_file('heart.csv', 'https://storage.googleapis.com/applied-dl/heart.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6BXRPD2-xtQ1"
      },
      "source": [
        "Read the csv file using pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UEfJ8TcMpe-2",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(csv_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8FkK6QIRpjd4",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_MOAKz654CT5",
        "colab": {}
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ww4lRDCS3qPh"
      },
      "source": [
        "Convert `thal` column which is an `object` in the dataframe to a discrete numerical value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LmCl5R5C2IKo",
        "colab": {}
      },
      "source": [
        "df['thal'] = pd.Categorical(df['thal'])\n",
        "df['thal'] = df.thal.cat.codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s4XA1SNW2QyI",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WWRhH6r4xxQu"
      },
      "source": [
        "## Load data using `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GuqmVVH_yApQ"
      },
      "source": [
        "Use `tf.data.Dataset.from_tensor_slices` to read the values from a pandas dataframe. \n",
        "\n",
        "One of the advantages of using `tf.data.Dataset` is it allows you to write simple, highly efficient data pipelines. Read the [loading data guide](https://www.tensorflow.org/alpha/guide/data) to find out more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2wwhILm1ycSp",
        "colab": {}
      },
      "source": [
        "target = df.pop('target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W6Yc-D3aqyBb",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "chEnp_Swsf0a",
        "colab": {}
      },
      "source": [
        "for feat, targ in dataset.take(5):\n",
        "  print ('Features: {}, Target: {}'.format(feat, targ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GzwlAhX6xH9Q"
      },
      "source": [
        "Since a `pd.Series` implements the `__array__` protocol it can be used transparently nearly anywhere you would use a `np.array` or a `tf.Tensor`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GnpHHkpktl5y",
        "colab": {}
      },
      "source": [
        "tf.constant(df['thal'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9XLxRHS10Ylp"
      },
      "source": [
        "Shuffle and batch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R3dQ-83Ztsgl",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.shuffle(len(df)).batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bB9C0XJkyQEk"
      },
      "source": [
        "## Create and train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hvFUYZr7OLcL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FQd9PcPRpkP4",
        "colab": {}
      },
      "source": [
        "def get_compiled_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ybDzNUheqxJw",
        "colab": {}
      },
      "source": [
        "model = get_compiled_model()\n",
        "model.fit(train_dataset, epochs=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d6V_6F_MBiG9"
      },
      "source": [
        "## Alternative to feature columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X63B9vDsD8Ly"
      },
      "source": [
        "Passing a dictionary as an input to a model is as easy as creating a matching dictionary of `tf.keras.layers.Input` layers, applying any pre-processing and stacking them up using the [functional api](../../guide/keras/functional.ipynb). You can use this as an alternative to [feature columns](../keras/feature_columns.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FwQ47_WmOBnY",
        "colab": {}
      },
      "source": [
        "inputs = {key: tf.keras.layers.Input(shape=(), name=key) for key in df.keys()}\n",
        "x = tf.stack(list(inputs.values()), axis=-1)\n",
        "\n",
        "x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_func = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "model_func.compile(optimizer='adam',\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qSCN5f_vUURE"
      },
      "source": [
        "The easiest way to preserve the column structure of a `pd.DataFrame` when used with `tf.data` is to convert the `pd.DataFrame` to a `dict`, and slice that dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wUjRKgEhPZqK",
        "colab": {}
      },
      "source": [
        "dict_slices = tf.data.Dataset.from_tensor_slices((df.to_dict('list'), target.values)).batch(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WWRaiwxeyA9Z",
        "colab": {}
      },
      "source": [
        "for dict_slice in dict_slices.take(1):\n",
        "  print (dict_slice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8nTrfczNyKup",
        "colab": {}
      },
      "source": [
        "model_func.fit(dict_slices, epochs=15)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}